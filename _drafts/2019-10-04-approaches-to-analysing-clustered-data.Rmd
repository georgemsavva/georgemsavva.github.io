---
title: Analysis of Clustered Data Part 3. Approaches to analysing clustered data
author: George Savva
date: '2019-10-04'
slug: approaches-to-analysing-clustered-data
output: 
  md_document:
    variant: markdown_github
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

``` {r echo=FALSE}

library(lmerTest)
library(ggplot2)


```

We saw in the last post that analysing clustered data using a standard tool such as a t-test will lead to increased type-1 error.

So how should we approach data like this?

We could take the average value over each cluster and analyse that with a t-test (effectively treating each mouse as a 'technical' replicate, and cage as a 'biological' or true replicate).  Or we could use a statistical model that incorporates clustering such as a linear mixed model (analogous to a repeated measures ANOVA).

These approaches are compared below.  What should concern us in each case is that the type 1 error is controlled at the nominal level (5% when we set p<0.05 as our threshold for statistical significance), and once that condition is satisfied that the test is as powerful as possible.

First, we'll adapt our simulation function from last time to return the data frame of clustered data without conducting any tests.

``` {r }
library(lmerTest)
library(ggplot2)
simData <- function( a=100, b=10, sd=10, icc=0.2, cageN = c(3,3,4)){
  x <- rep(c(0,1), each=sum(cageN)) #  x is the treatment group
  cageID <- rep(1:(length(cageN)*2), c(cageN, cageN))
  dat <- data.frame(x, cageID)
  sd1 <- sd*sqrt(1-icc)
  sd2 <- sd*sqrt(icc)
  cageeffect <- data.frame(cageID=1:(length(cageN)*2), ce=rnorm(length(cageN)*2, 0, sd2))
  dat <- merge(dat, cageeffect)
  dat$y <- a + rnorm(2*sum(cageN), b*dat$x + dat$ce, sd1) #  y is the response
  dat
}

```


Next we have a function to take a simulated dataset and return three p-values, one for a t-test with no correction (which we expect to be wrong), one for a linear mixed model, and finally for a t-test of cage means rather than mouse means.

``` {r }

testDat <- function(dat){
   lmer1 <- lmer(data=dat , y~x + (1|cageID))
   lm2 <- lm( data=dat, y~x )
   dat2 <- aggregate(data=dat, cbind(y,x) ~ cageID, FUN=mean)
   lm3 <- lm( data=dat2, y~x )
   
  return(c(   lm=summary(lm2)$coef["x","Pr(>|t|)"],
              mixed=summary(lmer1)$coef["x","Pr(>|t|)"],
   tech=summary(lm3)$coef["x","Pr(>|t|)"]))
   }
  

```

Now if we simulate 1000 datasets with b=0 (no effect) but with a small cage effect (and with two cages of five mice per cage in each group) then we see:

``` {r }


dats <- replicate( n=1000, simData(b=0,sd=10,icc=0.2, cageN = c(5,5)), simplify=FALSE)
tests <- sapply( dats, testDat )
tests2 <- reshape2::melt(t(tests), value.name="p")
library(ggplot2)
l1 <- c(mixed="Mixed effects model",lm="Linear model",tech="T-test over cages")

ggplot(data=tests2, aes(x=p)) + 
  geom_histogram(binwidth = 0.05,color="black", fill="red") + 
  theme_bw() +
  facet_wrap(~Var2, labeller=labeller(Var2=l1)) +  
  geom_hline(yintercept=500)

```

As expected the usual t-test has a very high error rate.  The mixed effects model is much better, but has a slightly odd p-value distribution toward the lower end.  The t-test averaged over cages works perfectly (as it should, because we meet the assumptions for this test even though it is N=2 per group)

Note - I get a lot of warnings from lmer() when I attempt to fit a mixed effects model that my test is 'singular'.  These are cases in which the 'between cages' variance is being estimated to be zero.  When this happens lmer() (actually lmertest) returns the same estimates and p-values as lm, that is the linear model without the random effect of cage included.  So this is what I am accepting as lmer's answer in this case.

# Power

Now lets see how powerful each test is, by setting a positive value for b (our usual 10g) to check how often this is detected. 

``` {r }

datsb10 <- replicate( n=1000, simData(b=10,sd=10,icc=0.2, cageN = c(5,5)), simplify = FALSE)
testsb10 <- sapply( datsb10, testDat )
testsb10_long <- reshape2::melt(t(testsb10), value.name="p")

ggplot(data=testsb10_long, aes(x=p)) + 
  geom_histogram(binwidth = 0.05,color="black", fill="red") + 
  theme_bw() +
  facet_wrap(~Var2, labeller=labeller(Var2=l1))

aggregate(data=testsb10_long , p~Var2 , FUN=function(x) mean(x<0.05))

```

So in this case it looks as if the linear mixed model is more powerful than the t-test using data averaged over cages.  If we repeate the analysis from the previous post, changing the true ICC and the cage layout we can see whether this is generally true:

``` {r }
# Change 'errorrate' so it returns a series of vectors.
errorrate2 <- function(icc=0.2, cageN=c(5,5),b=10, sd=10,n=100){
  dat <- replicate( n=n, simData(b=b,sd=sd,icc=icc, cageN = cageN), simplify = FALSE)
tests <- sapply( dat, testDat )
testslong <- reshape2::melt(t(tests), value.name="p")
aggregate(data=testslong , p~Var2 , FUN=function(x) mean(x<0.05))
}  

ers <- expand.grid(test=c("lm", "mixed", "tech"), layout=c("5,5","3,3,4","2,2,2,2,2"),
            icc=c(0.0,0.1,0.2,0.3,0.4,0.5) )

errorrates <- list(NULL)
for(icc in c(0.0,0.1,0.2,0.3,0.4,0.5)){
  for(layout in list(c(5,5), c(3,3,4), c(2,2,2,2,2))) {
  errorrates <- c(errorrates, list(errorrate2(icc=icc, cageN=layout,n=1000)))
  }
}
  
ers <- data.frame(ers, power=unlist(lapply(errorrates, `[[`, 2)))
ggplot(ers , aes(x=icc, y=power, color=test)) + geom_line() + geom_point() + facet_wrap(~layout)

``` 

We see that:

* when there are two cages of five mice each (per group), the mixed model is consistently more powerful than the t-test averaged over cages, but both lose power as the clustering within groups increases.  
* For the designs with more than two cages per group, the mixed effect model and the t-test averaged over cages have roughly similar power.
* The more cages you can use, even keeping the number of mice the same, the more powerful your test will be.  
* But using the appropriate analysis for potentially clustered data still has implications for power, even when the data is not in fact clustered (that is when ICC=0).

Summary:

It is well known that we shouldn't treat co-housed animals as if they are independent, but this is often ignored in animal study analysis.    This simulation study has several important practical implications.

* Observations from units that are not independent must not be analysed as if they are independent
* Ignoring this can severely inflate error rates
* The correct analysis is often not very difficult
* Co-housing your mice means that you will need more mice than you would if you'd been able to treat them randomly and house them individually.
* So this need to be considered in your design and power calculation
